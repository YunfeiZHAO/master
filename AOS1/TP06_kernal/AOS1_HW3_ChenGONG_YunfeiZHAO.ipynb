{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AOS1-HW3-ChenGONG_YunfeiZHAO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtgBMJugHIwb"
      },
      "source": [
        "# Improving the Accuracy of Support Vector Machines\n",
        "\n",
        "AOS1 homework3\n",
        "\n",
        "author:\n",
        "Chen GONG\n",
        "Yunfei ZHAO\n",
        "\n",
        "date:\n",
        "19/oct/2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Oe4ms-CHNPt"
      },
      "source": [
        "## Introduction\n",
        "This homework is an analyse of improving SVM classifier accuracy in handwritten digits classification mission.\n",
        "\n",
        "* We improve model accuracy by incorporating knowledge about invariances of the problem.(pixel jittered in our case)\n",
        "\n",
        "* The data set contains 10 types of handwritten digit pictures from 0-9, and each picture is normalized to a size of 28x28. The data we need is downloaded from this website: http://yann.lecun.com/exdb/mnist/ . We get 4 files, then decompress them and put them in a folder with this file.\n",
        "* We inplemented the algorithm in paper:\n",
        "Chris J.C. Burges and Bernhard Schölkopf. “Improving the Accuracy and Speed of Support Vector Machines”. In: Advances in Neural Information Processing Systems 9. MIT Press, 1997, pp. 375–381.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxA4GABhGTF-"
      },
      "source": [
        "All the libraries we use are as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcIRz5UBNzw_"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import struct\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import cv2\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spRGaJ_lGi5W"
      },
      "source": [
        "# Data processing\n",
        "\n",
        "def read_image(file_name):\n",
        "    #First read the files in binary mode\n",
        "    file_handle=open(file_name,\"rb\")  \n",
        "    file_content=file_handle.read()   \n",
        "    offset=0\n",
        "    head = struct.unpack_from('>IIII', file_content, offset)  \n",
        "    offset += struct.calcsize('>IIII')\n",
        "    imgNum = head[1]  #Number of pictures\n",
        "    rows = head[2]   #width\n",
        "    cols = head[3]  #height\n",
        "    images=np.empty((imgNum , 784))\n",
        "    image_size=rows*cols  #size of one picture\n",
        "    fmt='>' + str(image_size) + 'B' #format of one picture\n",
        "\n",
        "    for i in range(imgNum):\n",
        "        images[i] = np.array(struct.unpack_from(fmt, file_content, offset))\n",
        "        # images[i] = np.array(struct.unpack_from(fmt, file_content, offset)).reshape((rows, cols))\n",
        "        offset += struct.calcsize(fmt)\n",
        "    return images\n",
        "\n",
        "#read the label of picture\n",
        "def read_label(file_name):\n",
        "    file_handle = open(file_name, \"rb\")  \n",
        "    file_content = file_handle.read()  \n",
        "\n",
        "    head = struct.unpack_from('>II', file_content, 0)  \n",
        "    offset = struct.calcsize('>II')\n",
        "\n",
        "    labelNum = head[1]  \n",
        "    # print(labelNum)\n",
        "    bitsString = '>' + str(labelNum) + 'B'  \n",
        "    label = struct.unpack_from(bitsString, file_content, offset)  \n",
        "    return np.array(label)\n",
        "\n",
        "def normalize_0_1(data):\n",
        "    data[data > 0] = 1\n",
        "    return data\n",
        "\n",
        "def loadDataSet():\n",
        "    train_x_filename=\"train-images.idx3-ubyte\"\n",
        "    train_y_filename=\"train-labels.idx1-ubyte\"\n",
        "    test_x_filename=\"t10k-images.idx3-ubyte\"\n",
        "    test_y_filename=\"t10k-labels.idx1-ubyte\"\n",
        "    train_x=read_image(train_x_filename)#60000*784 \n",
        "    train_y=read_label(train_y_filename)#60000*1\n",
        "    test_x=read_image(test_x_filename)#10000*784\n",
        "    test_y=read_label(test_y_filename)#10000*1\n",
        "\n",
        "    return train_x, test_x, train_y, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-EjqtdeOLLj",
        "outputId": "8051ca92-3176-442a-e04d-09722f2bedcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test=loadDataSet()\n",
        "# nomalise X to 0 and 1\n",
        "# X_train = normalize_0_1(X_train)\n",
        "# X_test = normalize_0_1(X_test)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS9UGaEdNtFo",
        "outputId": "112b2112-4081-439f-f2ac-9adfda010a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# An example of our X\n",
        "plt.imshow(X_train[1,:].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdae5befe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ztt4cFvHbRO"
      },
      "source": [
        "## Missions\n",
        "* Do the classification of digit '9' by tradiction SVM with hyperparameters provided by paper\n",
        "* Implement the  1-pixel jittered model proposed by the paper, and test the performance of this performance on digit '9'\n",
        "* Compare the performance (accuracy) of these two models\n",
        "* Explanation of the observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcVP2o-uWUcH"
      },
      "source": [
        "## Test with traditional SVM with cofiguration given by the paper\n",
        "As suggested in the paper，the parameters correspond to model ORIG \n",
        "* kernal: polynomial kernel $K(x, y) = (x·y)^5$\n",
        "* C =10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjIV-ZG_HRbI"
      },
      "source": [
        "To build a ten-class classifier, this procedure is carried out separately for ten binary classifiers. The following is an example for digit 0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fiat3XOjd6ag"
      },
      "source": [
        "y_train_0 = (y_train == 0) # True for all 9s, False for all other digits.\n",
        "y_test_0 = (y_test == 0)\n",
        "\n",
        "svc = SVC(C=10, kernel='poly', degree=5)\n",
        "svc.fit(X_train, y_train_0)\n",
        "y_pred_0 = svc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liW_prNpGy-V",
        "outputId": "bfe8ad2a-4972-4788-f875-b15658457d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(classification_report(y_test_0, y_pred_0))\n",
        "print(\"number of error for digit 0:\",confusion_matrix(y_test_0, y_pred_0)[0,1]+confusion_matrix(y_test_0, y_pred_0)[1,0])\n",
        "print(\"number of vector support for digit 0:\",svc.n_support_[0]+svc.n_support_[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      9020\n",
            "        True       0.99      0.99      0.99       980\n",
            "\n",
            "    accuracy                           1.00     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       1.00      1.00      1.00     10000\n",
            "\n",
            "number of error for digit 0: 23\n",
            "number of vector support for digit 0: 1790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyKre5zczgM8"
      },
      "source": [
        "In the paper, they create 10 classifier for 0-9 and in their result, digit '9' had the worst result(white when apply their method, the result has a big improve, so this choice is a little bit arbitrary). To simplify our mission, we will create only one classifier for digital '9'. Because The object of this homework is to analyse their method to improve the performance of SVM. So create 9 classifier and combine them to do the classification of 10 digits is not the most important part. For the digit classification method, we can realise this by doing the classification of one digit on these 10 classifiers and if the result is positive for several classifiers, we can compare the  estimated probability to chose which digit it is classified. But this process take long time. For us, training a tradition model and doing the prediction will take 30 minutes  and training a pixel jittered model and doing the prediction will take 60 minutes. As a matter of fact, for  pixel jittered model, we need to do the training process two times on the original dataset and new generated dataset by moving support vectors of the first model respectively  and also with more support vectors, the process for prediction is longer. So we need totally more then 900 minutes.  As we know that the core object to this homework is to analyse the improvement of  model accuracy by incorporating knowledge about invariances of the problem. We decide to take only the classifier of digit '9' as an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlF6V2tvdz8o"
      },
      "source": [
        "y_train_9 = (y_train == 9) # True for all 9s, False for all other digits.\n",
        "y_test_9 = (y_test == 9)\n",
        "\n",
        "svc = SVC(C=10, kernel='poly', degree=5)\n",
        "svc.fit(X_train, y_train_9)\n",
        "y_pred_9 = svc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec0FVIhvGwg_",
        "outputId": "894ce7c1-7527-4a49-965c-f051e12e0d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(classification_report(y_test_9, y_pred_9))\n",
        "print(\"number of error for digit 9:\",confusion_matrix(y_test_9, y_pred_9)[0,1]+confusion_matrix(y_test_9, y_pred_9)[1,0])\n",
        "print(\"number of vector support for digit 9:\",svc.n_support_[0]+svc.n_support_[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      1.00      1.00      8991\n",
            "        True       0.98      0.94      0.96      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.98      0.97      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "number of error for digit 9: 83\n",
            "number of vector support for digit 9: 3721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M985OUwDzjx_"
      },
      "source": [
        "Considering that the values in the data set y (the set of results) are True and False, we want to know if changing them to 0 and 1 will affect performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU78J3Syltq4"
      },
      "source": [
        "y_train_9 = (y_train == 9)*1\n",
        "y_test_9 = (y_test == 9)*1\n",
        "\n",
        "svc = SVC(C=10, kernel='poly', degree=5)\n",
        "svc.fit(X_train, y_train_9)\n",
        "y_pred_9 = svc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ndlsM-_yigT",
        "outputId": "d132cbbd-109f-4771-dd7d-b342e1d2c955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(classification_report(y_test_9, y_pred_9))\n",
        "print(\"If all values = 0 and 1, number of error for digit 9:\",confusion_matrix(y_test_9, y_pred_9)[0,1]+confusion_matrix(y_test_9, y_pred_9)[1,0])\n",
        "print(\"number of vector support for digit 9:\",svc.n_support_[0]+svc.n_support_[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      8991\n",
            "           1       0.98      0.94      0.96      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.98      0.97      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "If all values = 0 and 1, number of error for digit 9: 83\n",
            "number of vector support for digit 9: 3721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVbx2T3X2JL7"
      },
      "source": [
        "The result is not affected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olq1lvOJHP1y"
      },
      "source": [
        "## The method for improving generalization performance (the \"virtual support vector\" method)\n",
        "\n",
        "1. Train an SVM to generate a set of support vectors $\\{S_1,...,S_n\\}$  \n",
        "\n",
        "2.  Generate the artificial examples *(virtual support vectors)* by applying the desired invariance transformations to $\\{S_1,...,S_n\\}$. In our case, we take the points of support vectors. For each point we generate four new points by moving this point to up one pixel, down one pixel, left one pixel and right one pixel. We take these new points to create a new dataset which is 4 times of the old support vector set's size. (We will also do a comparsion to see if the result is better when include the points of old support vectors in the new dataset)\n",
        "\n",
        "3. Train new SVM model on the new dataset\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi4l9F2qCvQS"
      },
      "source": [
        "An example of translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKu9DvXXGzyy",
        "outputId": "13088aeb-d369-4b86-f6b8-c3f1791055c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "digit_9 = svc.support_vectors_[2000] #For example, the 2000th support vector\n",
        "digit_9_image = digit_9.reshape(28, 28)\n",
        "plt.imshow(digit_9_image, cmap = matplotlib.cm.binary,interpolation=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f195094c828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abW2CL1CG06q",
        "outputId": "a024fb58-a65b-4d2a-b16b-a99c27208d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "img = digit_9_image\n",
        "rows,cols = img.shape\n",
        "# Translation matrix M: [[1,0,x],[0,1,y]]\n",
        "M = np.float32([[1,0,1],[0,1,0]]) #Shift the 2000th support vector by one pixel to the right\n",
        "dst = cv2.warpAffine(img,M,(cols,rows))\n",
        "plt.imshow(dst, cmap = matplotlib.cm.binary,interpolation=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1947408550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKd45st-HYzV"
      },
      "source": [
        "\n",
        "We then generated new training data by translating the resulting support vectors by one pixel in each of four directions, and trained a new machine (using the same parameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJGpomgGG2tQ"
      },
      "source": [
        "VSV=[]\n",
        "VSV_y=[]\n",
        "for i in range(svc.support_vectors_.shape[0]):\n",
        "  digit_i = svc.support_vectors_[i]\n",
        "  digit_i_image = digit_i.reshape(28, 28)\n",
        "  rows,cols = digit_i_image.shape\n",
        "  M1 = np.float32([[1,0,1],[0,1,0]]) #Shifted one pixel to the right\n",
        "  M2 = np.float32([[1,0,0],[0,1,1]]) ##Shifted one pixel up\n",
        "  M3 = np.float32([[1,0,-1],[0,1,0]]) #Shifted one pixel to the left\n",
        "  M4 = np.float32([[1,0,0],[0,1,-1]]) ##Shifted one pixel down\n",
        "  dst1 = cv2.warpAffine(digit_i_image,M1,(cols,rows)).reshape(784,)\n",
        "  dst2 = cv2.warpAffine(digit_i_image,M2,(cols,rows)).reshape(784,)\n",
        "  dst3 = cv2.warpAffine(digit_i_image,M3,(cols,rows)).reshape(784,)\n",
        "  dst4 = cv2.warpAffine(digit_i_image,M4,(cols,rows)).reshape(784,)\n",
        "  VSV.append(dst1)\n",
        "  VSV.append(dst2)\n",
        "  VSV.append(dst3)\n",
        "  VSV.append(dst4)\n",
        "  if i < svc.n_support_[0]:\n",
        "    VSV_y.append(False)\n",
        "    VSV_y.append(False)\n",
        "    VSV_y.append(False)\n",
        "    VSV_y.append(False)\n",
        "  else:\n",
        "    VSV_y.append(True)\n",
        "    VSV_y.append(True)\n",
        "    VSV_y.append(True)\n",
        "    VSV_y.append(True)\n",
        "VSV = pd.DataFrame(VSV)\n",
        "VSV_y = pd.DataFrame(VSV_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvNA29oVeARR",
        "outputId": "5143a0ac-8e48-43a6-b0c5-c2c12b901c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "svc = SVC(C=10, kernel='poly', gamma='auto', degree=5)\n",
        "svc.fit(VSV, VSV_y)\n",
        "y_pred_VSV = svc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gVHrc6AG7Pq",
        "outputId": "2f8f2502-eee2-428f-ef86-9666b37862cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(classification_report(y_test_9, y_pred_VSV))\n",
        "print(\"number of error after victual method for digit 9:\",confusion_matrix(y_test_9, y_pred_VSV)[0,1]+confusion_matrix(y_test_9, y_pred_VSV)[1,0])\n",
        "print(\"number of vector support after victual method for digit 9:\",svc.n_support_[0]+svc.n_support_[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      8991\n",
            "        True       0.98      0.97      0.98      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.98      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "number of error: 50\n",
            "number of vector support: 6666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7lK7zFrJB6J"
      },
      "source": [
        "x = np.arange(3)\n",
        "nerror = [83, 50, 59]\n",
        "nsv = [3721, 6666, 8747]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD19TznQJJ-r",
        "outputId": "289c2938-77f3-4c8c-9813-50f5526710f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.bar(x, nerror)\n",
        "plt.xticks(x, ('ORIG', 'VSV', 'VSV with old SV'))\n",
        "plt.ylabel('number of wrong prediction')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl4iyP0kJfRw",
        "outputId": "87d29a57-41ba-4d00-9562-b812ad6a393a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.bar(x, nsv)\n",
        "plt.xticks(x, ('ORIG', 'VSV', 'VSV with old SV'))\n",
        "plt.ylabel('number of support vectors')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqaNSgOPIBA9"
      },
      "source": [
        "## Explaination of the result\n",
        "\n",
        "We can see that the number of errors has decreased with the same test data set (at first 83 on the traditional SVM model and now 50 on the new SVM model trained on new dataset), but the number of support vectors has increased significantly(from 3721 to 6666). Although the performance has improved, the running speed has dropped.\n",
        "\n",
        "For performance improvement, we considered two reasons:\n",
        "\n",
        "1. For SVM, only model is only depends on the support vectors. So the information we get from the dataset is all saved in these support vectors. So these support vectors is the known invariant of the problems. And we used these know invariant to generate more data which make the model more robust and resist to the noise. Because we use the knowledge we know to provide more data to our model. For example we use 6000 samples to generate 3721 suport vector and if we want to genrate these new 6666 data, we may use more than 12000 samples and all these 3721 * 4 new point generated by old support vectors are useful because the are no far from the margin lines. So this is a kind of data augmentation by invariant known knowledge.\n",
        "\n",
        "2. As the quality of the training set becomes higher, because each vector of the new training set is changed from the support vector of the traditional method, they better than raw samples.\n",
        "\n",
        "3. As we have more support vectors, the variance of the model is lower than before, it will be less influenced by noise during the prediction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG7C-s-tIcjW"
      },
      "source": [
        "## What if we include points of old support vector in new dataset\n",
        "From the result, we can observe that the number of support vector is getting bigger and the performance is worst than the model without the old vector. We think maybe with too many points of support vectors, it got a overfitting problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNUbR1fR2UKr"
      },
      "source": [
        "VSV=[]\n",
        "VSV_y=[]\n",
        "for i in range(svc.support_vectors_.shape[0]):\n",
        "  digit_i = svc.support_vectors_[i]\n",
        "  digit_i_image = digit_i.reshape(28, 28)\n",
        "  rows,cols = digit_i_image.shape\n",
        "  M1 = np.float32([[1,0,1],[0,1,0]]) #Shifted one pixel to the right\n",
        "  M2 = np.float32([[1,0,0],[0,1,1]]) ##Shifted one pixel up\n",
        "  M3 = np.float32([[1,0,-1],[0,1,0]]) #Shifted one pixel to the left\n",
        "  M4 = np.float32([[1,0,0],[0,1,-1]]) ##Shifted one pixel down\n",
        "  dst1 = cv2.warpAffine(digit_i_image,M1,(cols,rows)).reshape(784,)\n",
        "  dst2 = cv2.warpAffine(digit_i_image,M2,(cols,rows)).reshape(784,)\n",
        "  dst3 = cv2.warpAffine(digit_i_image,M3,(cols,rows)).reshape(784,)\n",
        "  dst4 = cv2.warpAffine(digit_i_image,M4,(cols,rows)).reshape(784,)\n",
        "  VSV.append(dst1)\n",
        "  VSV.append(dst2)\n",
        "  VSV.append(dst3)\n",
        "  VSV.append(dst4)\n",
        "  VSV.append(digit_i)\n",
        "  if i < svc.n_support_[0]:\n",
        "    VSV_y.append(False)\n",
        "    VSV_y.append(False)\n",
        "    VSV_y.append(False)\n",
        "    VSV_y.append(False)\n",
        "    VSV_y.append(False)\n",
        "  else:\n",
        "    VSV_y.append(True)\n",
        "    VSV_y.append(True)\n",
        "    VSV_y.append(True)\n",
        "    VSV_y.append(True)\n",
        "    VSV_y.append(True)\n",
        "VSV = pd.DataFrame(VSV)\n",
        "VSV_y = pd.DataFrame(VSV_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuon4lC526W3",
        "outputId": "04159f17-b58b-4005-afee-18adb06f4e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "svc = SVC(C=10, kernel='poly', gamma='auto', degree=5)\n",
        "svc.fit(VSV, VSV_y)\n",
        "y_pred_VSV = svc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYE3caRk2-ZN",
        "outputId": "8754df07-292b-432e-ff23-1af2493a2aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(classification_report(y_test_9, y_pred_VSV))\n",
        "print(\"If we add the original vector support to the new data set，number of error after victual method for digit 9:\",confusion_matrix(y_test_9, y_pred_VSV)[0,1]+confusion_matrix(y_test_9, y_pred_VSV)[1,0])\n",
        "print(\"number of vector support after victual method for digit 9:\",svc.n_support_[0]+svc.n_support_[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      8991\n",
            "           1       0.98      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.98      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "If we add the original vector support to the new data set，number of error after victual method for digit 9: 59\n",
            "number of vector support after victual method for digit 9: 8747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSIur5JIIFjp"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "The method of Burges and Schölkopf, virtual support vector, is an effective way to improve performance of SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTRZ9ZfLIHR5"
      },
      "source": [
        "## Go further\n",
        "During the experiment, we found some problems.\n",
        "1. For each data set, the difference between the number of positive and negative values is very large. Negative values are about nine times more than positive values. We think about whether this will affect the accuracy of the model, because for him, predicting a number as an error still has an accuracy of 90%. This explains to why in classification_report, all indicators of class False are better than those of class True\n",
        "2. When preprocessing data, we think about whether it should be normalized. Because the stroke marks on the edges of the numbers are lighter, if they are uniformly classified as 1 and the areas with no traces are classified as 0, performance may be affected.\n",
        "3. We consider whether we can more accurately describe the performance of the method if we test nine sets separately and integrate all the results. However, due to time constraints, each training set on our computer took 30 minutes (using the original SVM) to 60 minutes (using the virtual support vector), and we have no time to test all the sets."
      ]
    }
  ]
}