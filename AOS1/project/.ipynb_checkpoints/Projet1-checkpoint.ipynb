{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "usAfuNrzptHY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import dot\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "WrNOQNRSqGk6"
   },
   "outputs": [],
   "source": [
    "def get_pi_hat(pd_serie, z):\n",
    "    # get the proportion of class z\n",
    "    return sum(pd_serie == z)/len(pd_serie)\n",
    "\n",
    "\n",
    "def Gaussian_empirical_parameters(X, Y, z1=1, z2=2):\n",
    "    # get gaussian empirical parameters from data\n",
    "    pi_hat1 = get_pi_hat(Y, z1) # portion of class1\n",
    "    pi_hat2 = get_pi_hat(Y, z2) # portion of class2\n",
    "    mu1 = X[Y==z1].mean(axis=0) # mean of class1\n",
    "    mu2 = X[Y==z2].mean(axis=0) # mean of class2 \n",
    "    print(\"hello\")\n",
    "    X_1 = X[Y==z1]\n",
    "    X_2 = X[Y==z2]\n",
    "    n_1 = len(X_1)\n",
    "    n_2 = len(X_2)\n",
    "\n",
    "    x1_sub_mu1=np.array(X_1-mu1)\n",
    "    x2_sub_mu2=np.array(X_2-mu2)\n",
    "\n",
    "    V_1 = (x1_sub_mu1.T@x1_sub_mu1)/n_1\n",
    "    V_2 = (x2_sub_mu2.T@x2_sub_mu2)/n_2\n",
    "    return pi_hat1, pi_hat2, n1, n2, mu1, mu2, V_1, V_2\n",
    "\n",
    "\n",
    "def is_pos_def(x):\n",
    "    # verify if x is positive definite\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "bYoQPQS7qGea"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/bcw.csv')\n",
    "Y = data.z.to_numpy()\n",
    "X = data.drop(columns=[\"z\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "dRa71QN6BLhB"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "W3Icq-4GqGrD",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9f37468a5e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtheta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussian_empirical_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-6c4aaaab9dbe>\u001b[0m in \u001b[0;36mGaussian_empirical_parameters\u001b[0;34m(X, Y, z1, z2)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpi_hat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pi_hat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# portion of class1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpi_hat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pi_hat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# portion of class2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# mean of class1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmu2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mean of class2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hello\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "theta1, theta2, n1, n2, mu1, mu2, cov_1, cov_2 = Gaussian_empirical_parameters(y_train, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.96396396, 1.30630631, 1.41441441, 1.34684685, 2.10810811,\n",
       "       2.41441441, 2.08333333, 1.26126126, 1.06531532])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[Y==1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(is_pos_def(cov_1))\n",
    "print(is_pos_def(cov_2))\n",
    "print(check_symmetric(cov_1))\n",
    "print(check_symmetric(cov_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_Gaussian_DA(X, Y, z1, z2, mu, kappa, Lambda, nu=None):\n",
    "    ''' Gaussian DA with Gaussian inverse-Wishart prior\n",
    "        the maximum-likelihood estimated mu and sigma by posterior distribution\n",
    "        We suppose these two class have the same prior distribution for the parameters\n",
    "    '''\n",
    "    _, _, n_1, n_2, Xm_1, Xm_2, V_1, V_2 = Gaussian_empirical_parameters(X, Y, z1=z1, z2=z2)\n",
    "\n",
    "    mu_hat_1 = (n_1 * Xm_1 + kappa * mu)/(n1 + kappa)\n",
    "    mu_hat_2 = (n_2 * Xm_2 + kappa * mu)/(n2 + kappa)\n",
    "    \n",
    "    d = X.shape[1]\n",
    "    if nu is None:\n",
    "        nu = X.shape[1] + 1\n",
    "    \n",
    "    sigma_hat_1 = (n_1 * V_1 + ((n1 * kappa)/(n1 + kappa)) * dot(Xm_1 - mu,(Xm_1 - mu).T) + inv(Lambda))/(n_1 + nu + d + 2)\n",
    "    sigma_hat_2 = \n",
    "\n",
    "\n",
    "    V_1 = (x1_sub_mu1.T@x1_sub_mu1)/n_1\n",
    "    V_2 = (x2_sub_mu2.T@x2_sub_mu2)/n_2\n",
    "    return pi_hat1, pi_hat2, mu1, mu2, V_1, V_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "1Cqni8DogQAN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LvHIPPWgWxv"
   },
   "source": [
    "##Compare the results with those obtained with quadratic logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "v8hYl9ZvgQDo",
    "outputId": "55fa9113-ea01-407b-9997-6b9a49642b53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('polynomialfeatures',\n",
       "                 PolynomialFeatures(degree=2, include_bias=False,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "cls = LogisticRegression()\n",
    "pipe = make_pipeline(poly, cls)\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "ZUVzxC-wgQ1p",
    "outputId": "2f2a33de-0397-4f03-a364-29115d47492a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1,\n",
       "       1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1,\n",
       "       1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "k0nUo4XtgTT3",
    "outputId": "a1ca5429-5050-4ea3-e830-aa3005003fcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9170731707317074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, pipe.predict(x_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "skiM04RHgTXX",
    "outputId": "af4dfe58-14f1-43d7-b76b-ea100cfd562f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,   9],\n",
       "       [  8,  62]])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pipe.predict(x_test), labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "id": "82US7OKfgTaZ",
    "outputId": "00cedf57-2982-4169-ac01-84b9b5d619dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.93      0.94       135\n",
      "           2       0.87      0.89      0.88        70\n",
      "\n",
      "    accuracy                           0.92       205\n",
      "   macro avg       0.91      0.91      0.91       205\n",
      "weighted avg       0.92      0.92      0.92       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pipe.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projet1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
