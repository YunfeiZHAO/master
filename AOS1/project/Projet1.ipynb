{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3442c0da4a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pi_hat(pd_serie, z):\n",
    "    # get the proportion of class z\n",
    "    return sum(pd_serie == z)/len(pd_serie)\n",
    "\n",
    "\n",
    "def Gaussian_empirical_parameters(X, Y, z1=1, z2=2):\n",
    "    # get gaussian empirical parameters from data\n",
    "    pi_hat1 = get_pi_hat(Y, z1) # portion of class1\n",
    "    pi_hat2 = get_pi_hat(Y, z2) # portion of class2\n",
    "    X_1 = X[Y==z1]\n",
    "    X_2 = X[Y==z2]\n",
    "    mu1 = X_1.mean(axis=0)\n",
    "    mu2 = X_2.mean(axis=0)\n",
    "    n_1 = len(X_1)\n",
    "    n_2 = len(X_2)\n",
    "\n",
    "    x1_sub_mu1=np.array(X_1-mu1)\n",
    "    x2_sub_mu2=np.array(X_2-mu2)\n",
    "\n",
    "    V_1 = (x1_sub_mu1.T@x1_sub_mu1)/n_1\n",
    "    V_2 = (x2_sub_mu2.T@x2_sub_mu2)/n_2\n",
    "    return pi_hat1, pi_hat2, n_1, n_2, mu1, mu2, V_1, V_2\n",
    "\n",
    "\n",
    "def is_pos_def(x):\n",
    "    # verify if x is positive definite\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "dRa71QN6BLhB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/bcw.csv')\n",
    "Y = data.z.to_numpy()\n",
    "X = data.drop(columns=[\"z\"]).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "theta1, theta2, n1, n2, mu1, mu2, cov_1, cov_2 = Gaussian_empirical_parameters(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(is_pos_def(cov_1))\n",
    "print(is_pos_def(cov_2))\n",
    "print(check_symmetric(cov_1))\n",
    "print(check_symmetric(cov_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_Gaussian_DA(X, Y, mu, kappa, Lambda, z1=1, z2=2, nu=None):\n",
    "    ''' Gaussian DA with Gaussian inverse-Wishart prior\n",
    "        the maximum-likelihood estimated mu and sigma by posterior distribution\n",
    "        We suppose these two class have the same prior distribution for the parameters\n",
    "    '''\n",
    "    _, _, n_1, n_2, Xm_1, Xm_2, V_1, V_2 = Gaussian_empirical_parameters(X, Y, z1=z1, z2=z2)\n",
    "\n",
    "    mu_hat_1 = (n_1 * Xm_1 + kappa * mu)/(n1 + kappa)\n",
    "    mu_hat_2 = (n_2 * Xm_2 + kappa * mu)/(n2 + kappa)\n",
    "    \n",
    "    d = X.shape[1]\n",
    "    if nu is None:\n",
    "        nu = X.shape[1] + 1\n",
    "    m_mu_1 = (Xm_1 - mu).reshape(-1,1)\n",
    "    m_mu_2 = (Xm_2 - mu).reshape(-1,1)\n",
    "    sigma_hat_1 = (n_1 * V_1 + ((n1 * kappa)/(n1 + kappa)) * np.dot(m_mu_1,m_mu_1.T) + inv(Lambda))/(n_1 + nu + d + 2)\n",
    "    sigma_hat_2 = (n_2 * V_2 + ((n2 * kappa)/(n2 + kappa)) * np.dot(m_mu_2,m_mu_2.T) + inv(Lambda))/(n_2 + nu + d + 2)\n",
    "    return mu_hat_1, mu_hat_2, sigma_hat_1, sigma_hat_2\n",
    "\n",
    "def RGDA_prediction(X_train, y_train, X_test, y_test, mu, kappa, Lambda, z1=1, z2=2, nu=None):\n",
    "    mu_hat_1, mu_hat_2, sigma_hat_1, sigma_hat_2 = regularized_Gaussian_DA(X_train, y_train, mu, kappa, Lambda, z1, z2, nu)\n",
    "    p1 = multivariate_normal.pdf(X_test, mean=mu_hat_1, cov=sigma_hat_1)\n",
    "    p2 = multivariate_normal.pdf(X_test, mean=mu_hat_2, cov=sigma_hat_2)\n",
    "    y_pred = (p1 > p2) * -1 + 2\n",
    "    print(f'accuracy:\\n {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'confusion_matrix:\\n {confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "def run_RGDA_prediction(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    y = data.z.to_numpy()\n",
    "    X = data.drop(columns=[\"z\"]).to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=30)\n",
    "    d = X.shape[1]\n",
    "    mu = 0\n",
    "    kappa = 1\n",
    "    Lambda = np.eye(d)\n",
    "    RGDA_prediction(X_train, y_train, X_test, y_test, mu, kappa, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      " 0.9512195121951219\n",
      "confusion_matrix:\n",
      " [[127   8]\n",
      " [  2  68]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/bcw.csv')\n",
    "y = data.z.to_numpy()\n",
    "X = data.drop(columns=[\"z\"]).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "d = X.shape[1]\n",
    "mu = 0\n",
    "kappa = 1\n",
    "Lambda = np.eye(d)\n",
    "prediction(X_train, y_train, X_test, y_test, mu, kappa, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LvHIPPWgWxv"
   },
   "source": [
    "## Compare the results with those obtained with regulized quadratic logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_LR(X_train, y_train, X_test, y_test)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "cls_skl = SklearnLogisticRegression(max_iter=1000, solver='newton-cg', penalty='none')\n",
    "pipe_skl = make_pipeline(poly, cls_skl)\n",
    "pipe_skl.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig, axs = plt.subplots(1, 3, tight_layout=True)\n",
    "#sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"z\", data=Xy, ax=axs[0]) add_decision_boundary(pipe_skl, label=\"SkPolyLR\", ax=axs[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "v8hYl9ZvgQDo",
    "outputId": "55fa9113-ea01-407b-9997-6b9a49642b53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('polynomialfeatures',\n",
       "                 PolynomialFeatures(degree=2, include_bias=False,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "cls = LogisticRegression()\n",
    "pipe = make_pipeline(poly, cls)\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "ZUVzxC-wgQ1p",
    "outputId": "2f2a33de-0397-4f03-a364-29115d47492a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1,\n",
       "       1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1,\n",
       "       1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projet1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sy09",
   "language": "python",
   "name": "sy09"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
